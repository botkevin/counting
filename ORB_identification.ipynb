{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detect Keypoints\n",
    "# Help: https://docs.opencv.org/3.3.0/dc/dc3/tutorial_py_matcher.html\n",
    "#       https://achuwilson.wordpress.com/2011/08/05/object-detection-using-surf-in-opencv-part-1/\n",
    "#       https://opencv-python-tutroals.readthedocs.io/en/latest/py_tutorials/py_feature2d/py_orb/py_orb.html\n",
    "def detect(img1, img2, k):\n",
    "    # Using ORB here but we can also use surf/sift\n",
    "    orb = cv2.ORB_create()\n",
    "    # find the keypoints and descriptors with ORB\n",
    "    kp1, des1 = orb.detectAndCompute(img1,None)\n",
    "    kp2, des2 = orb.detectAndCompute(img2,None)\n",
    "    \n",
    "#     # If using FLANN based matcher, below are ORB recommended\n",
    "#     # parameters as per the FLANN doc.\n",
    "#     FLANN_INDEX_LSH = 6\n",
    "#     index_params= dict(algorithm = FLANN_INDEX_LSH,\n",
    "#                    table_number = 6, # 12\n",
    "#                    key_size = 12,     # 20\n",
    "#                    multi_probe_level = 1) #2\n",
    "#     # This is FLANN # of times recursive search \n",
    "#     # Higher number is more accurate at the cost\n",
    "#     # of more computation. Below is default value.\n",
    "#     search_params = dict(checks=50) \n",
    "#     flann = cv2.FlannBasedMatcher(index_params,search_params)\n",
    "#     matches = flann.knnMatch(des1,des2,k=2)\n",
    "\n",
    "    # create BFMatcher object\n",
    "    # NORM_HAMMING for ORB, NORM_L2(default) for SURF\n",
    "    bf = cv2.BFMatcher(cv2.NORM_HAMMING)\n",
    "    matches = bf.knnMatch(des1,des2, k=2)\n",
    "\n",
    "    # David Lowe's Ratio test \n",
    "    # http://www.cs.ubc.ca/~lowe/papers/ijcv04.pdf#page=20\n",
    "#     good = []\n",
    "#     for points in matches:\n",
    "#         prev_dist = 0\n",
    "#         prev = None\n",
    "#         for match in points:\n",
    "#             if prev_dist < 0.75*match.distance:\n",
    "#                 if prev != None:\n",
    "#                     good.append([prev])\n",
    "#             else:\n",
    "#                 break\n",
    "#         # if everything is close enough in distance,\n",
    "#         # that means none of the matches are good.\n",
    "#         good = []\n",
    "\n",
    "    # Apply ratio test\n",
    "    good = []\n",
    "    for m,n in matches:\n",
    "        if m.distance < .8 * n.distance:\n",
    "            good.append([m])\n",
    "\n",
    "            \n",
    "    # cv2.drawMatchesKnn expects list of lists as matches.\n",
    "    img3 = cv2.drawMatchesKnn(img1,kp1,img2,kp2,good, outImg = None, flags=2)\n",
    "    cv2.imshow('image',img3)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "detect(cv2.imread('screen.jpg',0),\n",
    "       cv2.imread('find_the_screen.jpg',0),\n",
    "      k=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.1.0) /io/opencv/modules/imgproc/src/color.cpp:182: error: (-215:Assertion failed) !_src.empty() in function 'cvtColor'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-3526484df92f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     33\u001b[0m                    \u001b[0mmatchesMask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmatchesMask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m                    flags = 0)\n\u001b[0;32m---> 35\u001b[0;31m \u001b[0mimg3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrawMatchesKnn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mkp1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mimg2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mkp2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmatches\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mdraw_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31merror\u001b[0m: OpenCV(4.1.0) /io/opencv/modules/imgproc/src/color.cpp:182: error: (-215:Assertion failed) !_src.empty() in function 'cvtColor'\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "img1 = cv2.imread('screen.png',0)          # queryImage\n",
    "img2 = cv2.imread('find_the_screen.png',0) # trainImage\n",
    "orb = cv2.ORB_create()\n",
    "# find the keypoints and descriptors with ORB\n",
    "kp1, des1 = orb.detectAndCompute(img1,None)\n",
    "kp2, des2 = orb.detectAndCompute(img2,None)\n",
    "\n",
    "# If using FLANN based matcher, below are ORB recommended\n",
    "# parameters as per the FLANN doc.\n",
    "FLANN_INDEX_LSH = 6\n",
    "index_params= dict(algorithm = FLANN_INDEX_LSH,\n",
    "               table_number = 6, # 12\n",
    "               key_size = 12,     # 20\n",
    "               multi_probe_level = 1) #2\n",
    "# This is FLANN # of times recursive search \n",
    "# Higher number is more accurate at the cost\n",
    "# of more computation. Below is default value.\n",
    "search_params = dict(checks=50) \n",
    "flann = cv2.FlannBasedMatcher(index_params,search_params)\n",
    "matches = flann.knnMatch(des1,des2,k=2)\n",
    "\n",
    "# Need to draw only good matches, so create a mask\n",
    "matchesMask = [[0,0] for i in range(len(matches))]\n",
    "# ratio test as per Lowe's paper\n",
    "for i,(m,n) in enumerate(matches):\n",
    "    if m.distance < 0.7*n.distance:\n",
    "        matchesMask[i]=[1,0]\n",
    "draw_params = dict(matchColor = (0,255,0),\n",
    "                   singlePointColor = (255,0,0),\n",
    "                   matchesMask = matchesMask,\n",
    "                   flags = 0)\n",
    "img3 = cv2.drawMatchesKnn(img1,kp1,img2,kp2,matches,None,**draw_params)\n",
    "plt.imshow(img3,),plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_matches(train, query, corr):\n",
    "        train_img = cv2.imread(train, 0)\n",
    "        query_img = cv2.imread(train, 0)\n",
    "        # Initiate SIFT detector\n",
    "        sift = cv2.ORB_CREATE()\n",
    "\n",
    "        # find the keypoints and descriptors with SIFT\n",
    "        kp1, des1 = sift.detectAndCompute(train_img, None)\n",
    "        kp2, des2 = sift.detectAndCompute(query_img, None)\n",
    "\n",
    "        # create BFMatcher object\n",
    "        bf = cv2.BFMatcher()\n",
    "        try:\n",
    "            matches = bf.knnMatch(des1, des2, k=2)\n",
    "        except cv2.error:\n",
    "            return False\n",
    "        good_matches = []\n",
    "        cluster = []\n",
    "        for m, n in matches:\n",
    "            img2_idx = m.trainIdx\n",
    "            img1_idx = m.queryIdx\n",
    "            (x1, y1) = kp1[img1_idx].pt\n",
    "            (x2, y2) = kp2[img2_idx].pt\n",
    "            # print(\"Comare %d to %d and %d to %d\" % (x1,x2,y1,y2))\n",
    "            if m.distance < 0.8 * n.distance and y2 > self.yThreshold and x2 < self.xThreshold:\n",
    "                good_matches.append([m])\n",
    "                cluster.append([int(x2), int(y2)])\n",
    "        if len(cluster) <= corr:\n",
    "            return False\n",
    "        self.kmeans = KMeans(n_clusters=1, random_state=0).fit(cluster)\n",
    "        new_cluster = self.compare_distances(train_img, cluster)\n",
    "        if len(new_cluster) == 0 or len(new_cluster) / len(cluster) < .5:\n",
    "            return False\n",
    "        img3 = cv2.drawMatchesKnn(\n",
    "            train_img, kp1, query_img, kp2, good_matches, None, flags=2)\n",
    "        if self._debug:\n",
    "            self.images.append(img3)\n",
    "            self.debug_matcher(img3)\n",
    "        return True "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'cv2.cv2' has no attribute 'ORB_CREATE'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-33-2e801c4a1e74>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_matches\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"screen.jpg\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"find_the_screen.jpg\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-32-1b8e3142f492>\u001b[0m in \u001b[0;36mget_matches\u001b[0;34m(train, query, corr)\u001b[0m\n\u001b[1;32m      3\u001b[0m         \u001b[0mquery_img\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0;31m# Initiate SIFT detector\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m         \u001b[0msift\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mORB_CREATE\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0;31m# find the keypoints and descriptors with SIFT\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'cv2.cv2' has no attribute 'ORB_CREATE'"
     ]
    }
   ],
   "source": [
    "get_matches(\"screen.jpg\", \"find_the_screen.jpg\", 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
